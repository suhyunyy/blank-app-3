import os
import streamlit as st

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools.retriever import create_retriever_tool
from langchain.prompts import ChatPromptTemplate
from langchain.agents import create_tool_calling_agent, AgentExecutor


# --------------------------------------------------------------------
# 1. Web Search Tool
# --------------------------------------------------------------------
def search_web():

# 1. Tavily Search Tool í˜¸ì¶œí•˜ê¸°
    search_tool = TavilySearchResults(
    k=6,name="web_search",description="Use this tool to search the web for up-to-date information."
    )

# --------------------------------------------------------------------
# 2. PDF Tool (ê³ ì • PDF ì‚¬ìš©)
# --------------------------------------------------------------------
def load_fixed_pdf():
    pdf_path = "data/SW ì¤‘ì‹¬ì‚¬íšŒ 5ì›”í˜¸ ì „ë¬¸.pdf"   

     # 2. PDF ë¡œë” ì´ˆê¸°í™” ë° ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    # 3. í…ìŠ¤íŠ¸ë¥¼ ì¼ì • ë‹¨ìœ„(chunk)ë¡œ ë¶„í• í•˜ê¸°
    #    - chunk_size: í•œ ë©ì–´ë¦¬ì˜ ìµœëŒ€ ê¸¸ì´
    #    - chunk_overlap: ë©ì–´ë¦¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ê¸¸ì´
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(documents)

    # 4. ë¶„í• ëœ ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•˜ì—¬ ë²¡í„° DB(FAISS)ì— ì €ì¥í•˜ê¸°
    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    

    # 5. ê²€ìƒ‰ê¸°(retriever) ê°ì²´ ìƒì„±
    retriever = vector.as_retriever(search_kwargs={"k": 5})
    
    # 6. retrieverë¥¼ LangChain Tool í˜•íƒœë¡œ ë³€í™˜ -> nameì€ pdf_searchë¡œ ì§€ì •
    retriever_tool = create_retriever_tool(
    retriever,
    name="pdf_search",
    description="Search for information inside the uploaded PDF"
    )

    return retriever_tool


# --------------------------------------------------------------------
# 3. Agent + Prompt êµ¬ì„±
# --------------------------------------------------------------------
def build_agent(tools):
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
        # 7. ì—¬ëŸ¬ë¶„ì˜ ì±—ë´‡ì— ë§ëŠ” system message ì‘ì„±í•˜ê¸°

     "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë‘ê°€ì§€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
     "- `pdf_search`: ì—…ë¡œë“œëœ 'í…Œë‹ˆìŠ¤ê¸°ìˆ ëª¨ìŒ.PDF' ë¬¸ì„œ ì•ˆì—ì„œ ë‹µì„ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n"
     "- `web_search`: ìµœì‹  ì •ë³´ë‚˜ 'í…Œë‹ˆìŠ¤ê¸°ìˆ ëª¨ìŒ.PDF'ì— ì—†ëŠ” ì¼ë°˜ ì§€ì‹ì„ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n\n"
     "ë„êµ¬ ì‚¬ìš© ê·œì¹™:\n"
     "1. í•­ìƒ ë¨¼ì € `pdf_search`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µì„ ì°¾ìœ¼ë ¤ê³  í•˜ì„¸ìš”.\n"
     "2. ë§Œì•½ `pdf_search`ì—ì„œ ê´€ë ¨ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ë¶ˆì¶©ë¶„í•˜ë‹¤ë©´, ê·¸ ë‹¤ìŒì— `web_search`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
     "3. ë‘ ë„êµ¬ ëª¨ë‘ ë‹µì„ ì œê³µí•˜ì§€ ëª»í•œë‹¤ë©´ 'ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•˜ì„¸ìš”."

        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}")
    ])
    # 8.agent ë° aagent_executor ìƒì„±í•˜ê¸°
    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)
    return agent_executor


# --------------------------------------------------------------------
# 4. Agent ì‹¤í–‰ í•¨ìˆ˜
# --------------------------------------------------------------------
def ask_agent(agent_executor, question: str):
    result = agent_executor.invoke({"input": question})
    answer = result["output"]

    # 9. intermediate_steps í†µí•´ ì‚¬ìš©íˆ´ì„ ì¶œë ¥í•  ìˆ˜ ìˆëŠ” ì½”ë“œ ì™„ì„±í•˜ê¸°
    # intermediate_stepsì—ì„œ ë§ˆì§€ë§‰ë§Œ ê°€ì ¸ì˜¤ê¸°
    if result.get("intermediate_steps"):
        last_action, _ = result["intermediate_steps"][-1]
        answer += f"\n\nì¶œì²˜:\n- Tool: {last_action.tool}, Query: {last_action.tool_input}"

    return f"ë‹µë³€:\n{answer}"
# --------------------------------------------------------------------
# 5. Streamlit ë©”ì¸
# --------------------------------------------------------------------
def main():
    # 10. ì—¬ëŸ¬ë¶„ì˜ ì±—ë´‡ì— ë§ëŠ” ìŠ¤íƒ€ì¼ë¡œ ë³€ê²½í•˜ê¸°
    st.set_page_config(page_title="í…Œë‹ˆìŠ¤ AI ë¹„ì„œ", layout="wide", page_icon="ğŸ¤–")
    st.image('data/kdn_image.jpg', width=800)
    st.markdown('---')
    st.title("ì•ˆë…•í•˜ì„¸ìš”! PDF + Web ê¸°ë°˜ RAG ì±—ë´‡ 'í…Œë‹ˆìŠ¤ AI ë¹„ì„œ' ì…ë‹ˆë‹¤")  

    with st.sidebar:
        openai_api = st.text_input("OPENAI API í‚¤", type="password")
        tavily_api = st.text_input("TAVILY API í‚¤", type="password")

    if openai_api and tavily_api:
        os.environ['OPENAI_API_KEY'] = openai_api
        os.environ['TAVILY_API_KEY'] = tavily_api

        ########ì•„ë˜ ë‘ ì¤„ì€ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”########
        tools = [search_web(), load_fixed_pdf()]
        agent_executor = build_agent(tools)
        ########ìœ„ì— ë‘ ì¤„ì€ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”########

        if "messages" not in st.session_state:
            st.session_state["messages"] = []

        user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

        if user_input:
            response = ask_agent(agent_executor, user_input)
            st.session_state["messages"].append({"role": "user", "content": user_input})
            st.session_state["messages"].append({"role": "assistant", "content": response})

        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    else:
        st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
